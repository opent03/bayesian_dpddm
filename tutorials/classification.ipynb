{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian D-PDDM Tutorial\n",
    "\n",
    "In this tutorial, we will use Bayesian D-PDDM to monitor deteriorating shifts in the UCI Heart Disease dataset. The preprocessed dataset is available in ``data/uci_data/``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "We begin with importing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_utils import UCIDataset\n",
    "data_dict = torch.load('data/uci_data/uci_heart_torch.pt')\n",
    "uci_dict = {}\n",
    "for k, data in data_dict.items():\n",
    "    data = list(zip(*data))\n",
    "    X, y = torch.stack(data[0]), torch.tensor(data[1], dtype=torch.int)\n",
    "    \n",
    "    # normalize\n",
    "    min_ = torch.min(X, dim=0).values\n",
    "    max_ = torch.max(X, dim=0).values\n",
    "    X = (X - min_) / (max_ - min_)\n",
    "    uci_dict[k] = UCIDataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ``train`` to train the base model, ``valid`` to validate the base model. Then, ``valid`` will be used to train the distribution of i.i.d. disagreement rates Phi.\n",
    "\n",
    "We will monitor on both ``train`` and ``iid_test`` in order to validate that our monitor is well-calibrated, i.e. it resists flagging in-distribution unseen samples. \n",
    "\n",
    "Finally, we monitor ``ood_test`` to assert that our monitor detects deteriorating changes from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "dataset_dict['train'] = uci_dict['train']\n",
    "dataset_dict['valid'] = uci_dict['val']\n",
    "dataset_dict['dpddm_train'] = uci_dict['val']\n",
    "dataset_dict['dpddm_id'] = uci_dict['iid_test']\n",
    "dataset_dict['dpddm_ood'] = uci_dict['ood_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Bayesian D-PDDM components\n",
    "\n",
    "Bayesian D-PDDM involves two primary components: \n",
    "    \n",
    "- the base model\n",
    "- the monitor\n",
    "\n",
    "The base model will depend on the data modality. For tabular data, we work with ``MLPModel``.  For images, we work with ``ConvModel``.\n",
    "The monitor takes in a base model, training and validation datasets, and a configuration file. We parse these using ``hydra-core``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from bayesian_dpddm import MLPModel, DPDDMBayesianMonitor\n",
    "from experiments.utils import get_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize(config_path='../experiments/configs', version_base='1.2')\n",
    "args = hydra.compose(config_name=\"uci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config, train_config = get_configs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = MLPModel(model_config, train_size=len(dataset_dict['train']))\n",
    "monitor = DPDDMBayesianMonitor(\n",
    "        model=base_model,\n",
    "        trainset=dataset_dict['train'],\n",
    "        valset=dataset_dict['valid'],\n",
    "        train_cfg=train_config,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Classifier Training\n",
    "\n",
    "We are now ready to train the model per our configurations. Simply run ``monitor.train_model``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:06,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, train loss: 180.0914\n",
      "Epoch:  0, valid loss: 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:01<00:05,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train loss: 175.2960\n",
      "Epoch: 10, valid loss: 0.6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:02<00:03,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, train loss: 170.7342\n",
      "Epoch: 20, valid loss: 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:03<00:02,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, train loss: 166.2854\n",
      "Epoch: 30, valid loss: 0.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:05<00:01,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, train loss: 161.8846\n",
      "Epoch: 40, valid loss: 0.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "output_metrics = monitor.train_model(tqdm_enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the maximum i.i.d. disagreement rate distribution\n",
    "\n",
    "We now have a base Bayesian model fitted to the training data. We now seek the disagreement rate with respect to our base classifier of models that:\n",
    "\n",
    "- agree with our base classifier on the training data\n",
    "- disagree with our base classifier on unseen i.i.d. data\n",
    "\n",
    "In order to achieve this, we batch sample from our belief over the decision surface, and repeatedly select the decision surface with the strongest disagreement rate. We collect these disagreement rates into model.Phi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 188.54it/s]\n"
     ]
    }
   ],
   "source": [
    "monitor.pretrain_disagreement_distribution(dataset=dataset_dict['dpddm_train'],\n",
    "                                           n_post_samples=args.dpddm.n_post_samples,\n",
    "                                           data_sample_size=args.dpddm.data_sample_size,\n",
    "                                           Phi_size=args.dpddm.Phi_size, \n",
    "                                           temperature=args.dpddm.temp,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute FPRs and TPRs\n",
    "\n",
    "We are essentially done. Our monitor has the essential components:\n",
    "\n",
    "- a trained base classifier on i.i.d. data\n",
    "- a trained distribution of i.i.d. disagreement rates\n",
    "\n",
    "This base classifier is now ready to be deployed on any deployment data, as long as we monitor periodically by running either ``monitor.dpddm_test`` or ``monitor.repeat_tests`` (for repeated testing, useful to compute statistics) on future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 185.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_train: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 192.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_id: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 191.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_ood: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "dis_rates = {}\n",
    "\n",
    "for k,dataset in {\n",
    "    'dpddm_train': dataset_dict['dpddm_train'],\n",
    "    'dpddm_id': dataset_dict['dpddm_id'],\n",
    "    'dpddm_ood': dataset_dict['dpddm_ood']\n",
    "}.items():\n",
    "    rate, max_dis_rates = monitor.repeat_tests(n_repeats=args.dpddm.n_repeats,\n",
    "                                    dataset=dataset, \n",
    "                                    n_post_samples=args.dpddm.n_post_samples,\n",
    "                                    data_sample_size=args.dpddm.data_sample_size,\n",
    "                                    temperature=args.dpddm.temp\n",
    "                                    )\n",
    "    print(f\"{k}: {rate}\")\n",
    "    stats[k] = rate\n",
    "    dis_rates[k] = (np.mean(max_dis_rates), np.std(max_dis_rates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpddm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
